{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMgBgKk47/qNIfbZZnEFpP7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oifkI-TLcHmK"},"outputs":[],"source":["import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras import models,datasets,layers\n","import numpy as np"]},{"cell_type":"code","source":["from keras.utils import to_categorical\n","from keras.preprocessing.sequence import pad_sequences\n","# Load IMDb dataset\n","(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=10000)\n","\n","# Pad sequences to have the same length\n","max_length = 500  # choose an appropriate length\n","train_data = pad_sequences(train_data, maxlen=max_length, padding='post')\n","test_data = pad_sequences(test_data, maxlen=max_length, padding='post')\n","\n","# Convert labels to binary values\n","train_labels_binary = to_categorical(train_labels)\n","test_labels_binary = to_categorical(test_labels)"],"metadata":{"id":"KGDvqI6RcpRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model=models.Sequential()\n","model.add(layers.Dense(64,activation='tanh'))\n","model.add(layers.Dense(32,activation='tanh'))\n","model.add(layers.Dense(10))"],"metadata":{"id":"jDtmGhbLc76S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1 = models.Sequential()\n","model1.add(layers.Embedding(input_dim=5000, output_dim=32))\n","model1.add(layers.LSTM(64, activation='relu',return_sequences=True))\n","model1.add(layers.LSTM(32, activation='relu',return_sequences=True))\n","model1.add(layers.LSTM(10))\n","model1.add(layers.Dense(1, activation='relu'))"],"metadata":{"id":"B2mMDPnHdQco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"lq4BxgGNf5JV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1.fit(train_data, train_labels_binary, batch_size=2, epochs=2, validation_data=(test_data, test_labels_binary))"],"metadata":{"id":"wqjablUggDEc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import models, datasets, layers\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load IMDb dataset\n","(train_data, train_labels), (test_data, test_labels) = datasets.imdb.load_data(num_words=10000)\n","\n","# Pad sequences to have the same length\n","max_length = 500  # choose an appropriate length\n","train_data = pad_sequences(train_data, maxlen=max_length, padding='post')\n","test_data = pad_sequences(test_data, maxlen=max_length, padding='post')\n","\n","# Convert labels to binary values\n","train_labels_binary = to_categorical(train_labels)\n","test_labels_binary = to_categorical(test_labels)\n","\n","# Define the model\n","model = models.Sequential()\n","model.add(layers.Embedding(input_dim=10000, output_dim=32))\n","model.add(layers.LSTM(64, activation='tanh', return_sequences=True))\n","model.add(layers.LSTM(32, activation='tanh', return_sequences=True))\n","model.add(layers.LSTM(10, activation='tanh'))\n","model.add(layers.Dense(2, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(train_data, train_labels_binary, batch_size=2, epochs=2, validation_data=(test_data, test_labels_binary))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPOzH6m8zl5F","outputId":"6ad4e94d-4814-4a45-88cc-0e125386e2a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n","Epoch 1/2\n","  301/12500 [..............................] - ETA: 1:12:39 - loss: 0.6950 - accuracy: 0.5033"]}]}]}